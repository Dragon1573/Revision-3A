{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于条件随机场模型的中文分词算法\n",
    "\n",
    "[![GitHub license](https://img.shields.io/github/license/Dragon1573/Revision-3A?style=for-the-badge)](https://github.com/Dragon1573/Revision-3A/blob/master/LICENSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备语料库\n",
    "\n",
    "准备一个已经分好词的、规模足够庞大的语料库，用于条件随机场模型的参数学习。语料库由大量类似下面的句子组成，词语之间采用空格符分隔。\n",
    "\n",
    "> 尽管 印尼 中央 和 地方政府 已 派出 上千人 的 灭火队，但 由于 该 地区 长期 干旱 少 雨，所以 火势 至今 未 得到 有效 控制。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语料库特征初步学习\n",
    "\n",
    "需要在语料库的每个词组中分析出每个字的状态，如“收益”需要改为“收\\B 益\\E”。对语料库中每个分好的词添加状态信息，标记后的语句如下：\n",
    "\n",
    "> 尽\\B 管\\E 印\\B 尼\\E 中\\B 央\\E 和\\S 地\\S 方\\M 政\\M 府\\E 已\\S 派\\B 出\\E 上\\B 千\\M 人\\E 的\\S 灭\\B 火\\M 队\\E ，\\S 但\\S 由\\B 于\\E 该\\S 地\\B 区\\E 长\\B 期\\E 干\\B 旱\\E 少\\S 雨\\S ，\\S 所\\B 以\\E 火\\B 势\\E 至\\B 今\\E 未\\S 得\\B 到\\E 有\\B 效\\E 控\\B 制\\E 。\\S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 词语特征学习\n",
    "\n",
    "词语特征学习是分词过程中非常重要的一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入程序包，并定义全局变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "\n",
    "LABEL = ('B', 'M', 'E', 'S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入需要分词的字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "请输入目标语句： 明天去上学\n"
     ]
    }
   ],
   "source": [
    "string = input('请输入目标语句：')\n",
    "start = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 语料库预处理\n",
    "\n",
    "语料库以标点符号区分每个句子，而在程序中，标点符号处不被认为是一个句子的开始/结束。所以我们需要对语料库执行预处理，将标点符号转换为起止标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('msr_training.utf8.ic', 'r', encoding='UTF-8') as database:\n",
    "    document = database.readlines()\n",
    "for line in range(len(document)):\n",
    "    if ord(document[line][0]) < 0x4E00 or ord(document[line][0]) > 0x9FA5:\n",
    "        document[line] = '^' + document[line][1:]\n",
    "if document[0][0] != '^':\n",
    "    document.insert(0, '^|S\\n')\n",
    "if document[-1][0] != '^':\n",
    "    document.append('^|S\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计各种字符在各种状态下出现的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R = {item: {label: 0 for label in ('Count', 'B', 'M', 'E', 'S')} for item in list(string)}\n",
    "for line in document:\n",
    "    if line[0] in R.keys():\n",
    "        R[line[0]]['Count'] += 1\n",
    "        R[line[0]][line[-2]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计各种字符在各种状态下出现的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in R.keys():\n",
    "    for label in LABEL:\n",
    "        try:\n",
    "            R[key][label] /= R[key]['Count']\n",
    "        except ZeroDivisionError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算每个字转移到下一个字的状态概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P = {word: {label_A: {label_B: 0 for label_B in LABEL} for label_A in LABEL} for word in string}\n",
    "for k in range(1, len(document) - 1):\n",
    "    if document[k][0] in P.keys():\n",
    "        P[document[k][0]][document[k][-2]][document[k + 1][-2]] += 1\n",
    "for word in P.keys():\n",
    "    for label_A in P[word].keys():\n",
    "        for label_B in P[word][label_A].keys():\n",
    "            try:\n",
    "                P[word][label_A][label_B] = P[word][label_A][label_B] / sum(P[word][label_A].values())\n",
    "            except ZeroDivisionError:\n",
    "                # 将其统一定义为0即可\n",
    "                P[word][label_A][label_B] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算词组复现概率\n",
    "\n",
    "#### 向前组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W_prev = {\n",
    "    string[k]: {state_A: {'All': 0} for state_A in LABEL}\n",
    "    for k in range(len(string))\n",
    "}\n",
    "temp = '^' + string + '^'\n",
    "for line in range(1, len(document) - 1):\n",
    "    for word in range(1, len(temp) - 1):\n",
    "        if document[line][0] == temp[word]:\n",
    "            W_prev[document[line][0]][document[line][-2]]['All'] += 1\n",
    "            if document[line - 1][0] == temp[word - 1]:\n",
    "                W_prev[document[line][0]][document[line][-2]].setdefault(document[line - 1][0], 0)\n",
    "                W_prev[document[line][0]][document[line][-2]][document[line - 1][0]] += 1\n",
    "for word in range(1, len(temp) - 1):\n",
    "    for state in W_prev[temp[word]].keys():\n",
    "        W_prev[temp[word]][state].setdefault(temp[word - 1], 0)\n",
    "        try:\n",
    "            W_prev[temp[word]][state][temp[word - 1]] = (\n",
    "                W_prev[temp[word]][state][temp[word - 1]]\n",
    "                / W_prev[temp[word]][state]['All']\n",
    "            )\n",
    "        except ZeroDivisionError:\n",
    "            W_prev[temp[word]][state][temp[word - 1]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 向后组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "W_subs = {string[k]: {state_A: {'All': 0} for state_A in LABEL} for k in range(len(string))}\n",
    "temp = '^' + string + '^'\n",
    "for line in range(1, len(document) - 1):\n",
    "    for word in range(1, len(temp) - 1):\n",
    "        if document[line][0] == temp[word]:\n",
    "            W_subs[document[line][0]][document[line][-2]]['All'] += 1\n",
    "            if document[line + 1][0] == temp[word + 1]:\n",
    "                W_subs[document[line][0]][document[line][-2]].setdefault(document[line + 1][0], 0)\n",
    "                W_subs[document[line][0]][document[line][-2]][document[line + 1][0]] += 1\n",
    "for word in range(1, len(temp) - 1):\n",
    "    for state in W_subs[temp[word]].keys():\n",
    "        W_subs[temp[word]][state].setdefault(temp[word + 1], 0)\n",
    "        try:\n",
    "            W_subs[temp[word]][state][temp[word + 1]] = (\n",
    "                W_subs[temp[word]][state][temp[word + 1]] / W_subs[temp[word]][state]['All']\n",
    "            )\n",
    "        except ZeroDivisionError:\n",
    "            W_subs[temp[word]][state][temp[word + 1]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入语句并切分为语素\n",
    "\n",
    "$4050472$行数据对于`Python3`来说实在过于庞大，如果对语料库整体进行处理，每一步产生的数据量都是爆炸式的。所以，我们将目标语句的输入放到特征训练之前，对目标语句执行针对性训练。这样可以剔除分词时不会被使用的数据，极大程度地压缩训练过程中产生的数据量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化字与状态的初始矩阵映射关系表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [{state: {'Rate': 0, 'Path': 'B'} for state in LABEL} for word in string]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算字与状态对应关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = '^' + string + '^'\n",
    "for state in LABEL:\n",
    "    S[0][state]['Rate'] = (\n",
    "        W_prev[string[0]][state]['^'] + W_subs[string[0]][state][string[1]] + R[string[0]][state]\n",
    "    )\n",
    "for word in range(2, len(temp) - 1):\n",
    "    for state_A in LABEL:\n",
    "        routes = [\n",
    "            P[temp[word - 1]][state_B][state_A] * S[word - 2][state_B]['Rate']\n",
    "            for state_B in LABEL\n",
    "        ]\n",
    "        maximum = max(routes)\n",
    "        S[word - 1][state_A]['Path'] = LABEL[routes.index(maximum)]\n",
    "        S[word - 1][state_A]['Rate'] = (\n",
    "            maximum + W_prev[temp[word]][state_A][temp[word - 1]]\n",
    "            + W_subs[temp[word]][state_A][temp[word + 1]] + R[temp[word]][state_A]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获得分词结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词标签： 明\\B 天\\E 去\\S 上\\S 学\\S \n",
      "分词结果： 明天 去 上 学 \n",
      "累计用时： 0:00:17.970923\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "temp = [rate['Rate'] for rate in S[-1].values()]\n",
    "index = temp.index(max(temp))\n",
    "current_state = tuple(S[-1].keys())[index]\n",
    "result.append('\\\\' + current_state + ' ')\n",
    "for word in range(len(string) - 1, -1, -1):\n",
    "    result.append(string[word])\n",
    "    result.append('\\\\' + S[word][current_state]['Path'] + ' ')\n",
    "    current_state = S[word][current_state]['Path']\n",
    "result.pop()\n",
    "result.reverse()\n",
    "result = ''.join(result)\n",
    "print('分词标签：', result)\n",
    "print('分词结果：', result.replace(r'\\B ', '').replace(r'\\M ', '').replace(r'\\E ', ' ').replace(r'\\S ', ' '))\n",
    "end = datetime.datetime.now()\n",
    "print('累计用时：', end - start)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
